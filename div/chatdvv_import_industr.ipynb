{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import INDUSTR XML to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/homebrew/Caskroom/miniconda/base/envs/chatdvv/lib/python3.10/site-packages (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 31 files\n"
     ]
    }
   ],
   "source": [
    "#import filenames of directory documents/pmg to pandas dataframe\n",
    "\n",
    "import os\n",
    "path = '../industr/'\n",
    "# path = '/Users/mweber/Dropbox/50_dev_projekte/DVV/dvv_content/industr'\n",
    "files = os.listdir(path)\n",
    "\n",
    "print(f\"Inserted {len(files)} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 2714283 \n",
      "Praktische Lösungsansätze für signifikante Effizienzsteigerungen \n",
      "id: 2717086 \n",
      "Albtraum\n",
      "Produktionsstillstand\n",
      "id: 2714056 \n",
      "Die Gefahren der\n",
      "Energiewende \n",
      "id: 2715265 \n",
      "Autonome Mobile Roboter rocken die Lagerlogistik \n",
      "id: 2715121 Industrial_Solutions\n",
      "Weniger Daten,  mehr Output\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from lxml import etree\n",
    "\n",
    "data_collection = []\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    # if collection.find_one({\"dateiname\": file}):\n",
    "    #     continue\n",
    "\n",
    "    tree = etree.parse(path + f'{file}')\n",
    "    root = tree.getroot()\n",
    "\n",
    "    data = []\n",
    "    for elem in root.findall('asset')[:5]:\n",
    "        # print element attribute \"magazine\"\n",
    "        print(f\"id: {elem.get('id')} {elem.get('magazine')}\")\n",
    "        print(elem.find('article/content/title').text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 10612 records into DataFrame\n",
      "quelle_id\n",
      "pi_AuD                     2555\n",
      "pi_PuA                     2080\n",
      "pi_EuE                     1857\n",
      "pi_E20                     1434\n",
      "pi_Industry_Forward         869\n",
      "pi_Industrial_Solutions     852\n",
      "pi_Next_Technology          813\n",
      "pi_                         152\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------\n",
    "# 21.06.2024 added fields quelle_id_embeddings, text_length\n",
    "#---------------------------------------------\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "data_collection = []\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    # if collection.find_one({\"dateiname\": file}):\n",
    "    #     continue\n",
    "\n",
    "    tree = etree.parse(path + f'{file}')\n",
    "    root = tree.getroot()\n",
    "\n",
    "    data = []\n",
    "    for elem in root.findall('asset'):\n",
    "\n",
    "        # Metadaten auslesen\n",
    "        artikel_id = elem.get('id')\n",
    "        quelle_id = \"pi_\" + elem.get('magazine')\n",
    "        jahrgang = \"\"\n",
    "        nummer = \"\"\n",
    "        datum = elem.get('modified_date')\n",
    "        seite_start = \"\"\n",
    "        seite_ende = \"\"\n",
    "\n",
    "        # Inhalt auslesen\n",
    "        title = elem.find('article/content/title').text\n",
    "        if elem.find('article/content/subtitle') is not None:\n",
    "            untertitel = elem.find('article/content/subtitle').text\n",
    "        else:\n",
    "            untertitel = \"leer\"\n",
    "        text_struktur = elem.find('article/content/text')\n",
    "        text_content = \"\".join(text_struktur.itertext())\n",
    "        text_length = len(text_content)\n",
    "\n",
    "        # Felder hinzufügen\n",
    "        ki_abstract = \"\"\n",
    "        date = datetime.strptime(datum, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        text_embeddings = {}\n",
    "        ki_embeddings = {}\n",
    "        quelle_id_embeddings = {}\n",
    "        \n",
    "        data.append([file, artikel_id, quelle_id, jahrgang, nummer, datum, seite_start, seite_ende, title, untertitel, text_content, ki_abstract, date, text_embeddings, ki_embeddings, quelle_id_embeddings, text_length])\n",
    "    \n",
    "    data_collection.extend(data)\n",
    "\n",
    "# read xml file and convert it to a pandas dataframe\n",
    "df = pd.DataFrame(data_collection, columns=['dateiname', 'artikel_id', 'quelle_id', 'jahrgang', 'nummer', 'datum', 'seite_start', 'seite_ende', 'titel', 'untertitel', 'text', 'ki_abstract', 'date', 'text_embeddings', 'ki_embeddings', 'quelle_id_embeddings', 'text_length'])\n",
    "# df.head(20)\n",
    "print(f\"Inserted {len(df)} records into DataFrame\")\n",
    "\n",
    "# print list of quelle_id grouped by count sorted by quelle_id\n",
    "print(df.groupby('quelle_id').size().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDB: Import Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "\n",
    "# Init MongoDB Client\n",
    "load_dotenv()\n",
    "mongoClient = MongoClient(os.environ.get('MONGO_URI_DVV'))\n",
    "database = mongoClient.dvv_content_pool\n",
    "collection = database.dvv_artikel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 10612 records into MongoDB\n"
     ]
    }
   ],
   "source": [
    "# Insert data into MongoDB usinf insert_many\n",
    "data_input = df.to_dict(orient='records')\n",
    "collection.insert_many(data_input)\n",
    "\n",
    "print(f\"Inserted {len(data_input)} records into MongoDB\")\n",
    "\n",
    "mongoClient.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/chatdvv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import chatdvv_module as myapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated embeddings for 10612 records.\n"
     ]
    }
   ],
   "source": [
    "myapi.generate_embeddings(input_field=\"quelle_id\", output_field=\"quelle_id_embeddings\", max_iterations=50000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
